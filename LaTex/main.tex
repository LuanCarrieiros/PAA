\documentclass{sbc2023}
\usepackage{float}
\usepackage{graphicx}
%\usepackage[utf8]{inputenc} % Geralmente não necessário com fontspec, que assume UTF-8
\usepackage[misc,geometry]{ifsym}
\usepackage{fontspec} % Para compilar com XeLaTeX ou LuaLaTeX
\usepackage{fontawesome}
\usepackage{academicons}
\usepackage{color}
\usepackage{hyperref}
\usepackage{aas_macros}
\usepackage[bottom]{footmisc}
\usepackage{supertabular}
\usepackage{afterpage}
\usepackage{url}
\usepackage{pifont}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{subcaption} 
\usepackage{tabularx}
\usepackage{booktabs}
\bibliography{references}



% Configura o biblatex
\usepackage[backend=biber, style=numeric, sorting=none]{biblatex}
\addbibresource{refs.bib} % Carrega o arquivo .bib

% Comando para evitar um aviso ou erro comum do biblatex com sbc2023 se o \cite já for quadrado
\DeclareCiteCommand{\cite}
  {\usebibmacro{prenote}}
  {\usebibmacro{citeindex}%
   \printtext[bibhyperref]{\printfield{labelprefix}\printfield{labelnumber}%
     \ifbool{bbx@subentry}{}{\printfield{entryset}}}}
  {\multicitedelim}
  {\usebibmacro{postnote}}

% Cores personalizadas
\definecolor{orcidlogo}{rgb}{0.37,0.48,0.13}
\definecolor{unilogo}{rgb}{0.16, 0.26, 0.58}
\definecolor{maillogo}{rgb}{0.58, 0.16, 0.26}
\definecolor{darkblue}{rgb}{0.0,0.0,0.0}

% Configuração de hiperlinks
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}
%\hypersetup{draft} % Manter comentado para ativar os hiperlinks no PDF final

% Metadados do Journal (verifique se SBCS aceita todos estes)
\jid{JBCS}
\jtitle{Journal of the Brazilian Computer Society, 2025, XX:1, }
\doi{10.5753/jbcs.2025.XXXXXX}
\copyrightstatement{This work is licensed under a Creative Commons Attribution 4.0 International License}
\jyear{2025}

\title[Image Similarity Search]{Comparative Performance Analysis of Data Structures for RGB Image Similarity Search: An Empirical Study}

% Autores e Afiliações
\author[Carrieiros et al. 2025]{
\affil{\textbf{Luan Barbosa Rosa Carrieiros}~\href{https://orcid.org/0000-0002-2431-8457}{\textcolor{orcidlogo}{\aiOrcid}}~\textcolor{blue}{\faEnvelopeO}~~[~\textbf{Pontifical Catholic University of Minas Gerais}~|\href{mailto:luan.rosa@sga.pucminas.br}{~\textbf{\textit{luan.rosa@sga.pucminas.br}}}~]}

\affil{\textbf{Diego Moreira Rocha}~\href{https://orcid.org/0000-0002-7110-2026}{\textcolor{orcidlogo}{\aiOrcid}}~~[~\textbf{Pontifical Catholic University of Minas Gerais}~|\href{mailto:diego.moreira@sga.pucminas.br}{~\textbf{\textit{diego.moreira@sga.pucminas.br}}}~]}

\affil{\textbf{Iago Fereguetti Ribeiro}~\href{https://orcid.org/0000-0003-3052-3016}{\textcolor{orcidlogo}{\aiOrcid}}~~[~\textbf{Pontifical Catholic University of Minas Gerais}~|\href{mailto:iago.fereguetti@sga.pucminas.br}{~\textbf{\textit{iago.fereguetti@sga.pucminas.br}}}~]}

\affil{\textbf{[Nome Randomico]}~\href{https://orcid.org/0000-0001-3195-1605}{\textcolor{orcidlogo}{\aiOrcid}}~~[~\textbf{Pontifical Catholic University of Minas Gerais}~|\href{mailto:randomico.nome@sga.pucminas.br}{~\textbf{\textit{randomico.nome@sga.pucminas.br}}}~]}
}

\begin{document}

\begin{frontmatter}
\maketitle

\begin{mail}
PUC Minas, Instituto de Ciências Exatas e Informática (ICEI), Av. Dom José Gaspar, 500, Coração Eucarístico, Belo Horizonte, MG, 30535-901, Brazil.
\end{mail}

\begin{abstract}
\textbf{Abstract.} \\
Image similarity search in RGB color space represents a fundamental challenge in computer vision and database systems, requiring efficient data structures to balance search performance with precision requirements. This paper presents a comprehensive empirical analysis of five distinct data structures for RGB image similarity search: \textbf{(i)} Linear Search (brute force baseline), \textbf{(ii)} Hash Search (3D spatial grid hashing), \textbf{(iii)} Hash Dynamic Search (adaptive expansion spatial hashing), \textbf{(iv)} Octree Search (3D recursive spatial tree), and \textbf{(v)} Quadtree Search (2D spatial tree projection). The algorithms were implemented in C++17 with compiler optimizations to ensure fair performance comparison. Extensive experiments were conducted on both synthetic datasets (100 to 50 million images) and real image collections (7,721 natural images across 8 categories) using Euclidean distance in RGB space with a similarity threshold of 50.0. Results reveal that Hash Search achieves superior search performance (18ms for 50M images) while Linear Search dominates insertion operations. Unexpectedly, 2D spatial structures (Quadtree) consistently outperformed 3D equivalents (Octree), and hash-based methods demonstrated a precision-speed trade-off, finding 85-86% of similar images compared to brute force methods. The study provides quantitative evidence for practical algorithm selection in image similarity applications and establishes performance benchmarks for RGB similarity search systems.
\end{abstract}

\begin{keywords}
Image similarity search; Data structures; Hash tables; Spatial indexing; Octree; Quadtree; RGB color space; Performance analysis; Empirical study; C++.
\end{keywords}

\end{frontmatter}


\section{Introduction}
\label{sec:intro}

Image similarity search in high-dimensional color spaces is a cornerstone problem in computer vision, content-based image retrieval, and multimedia database systems. The challenge lies in efficiently indexing and querying large collections of images based on perceptual similarity, typically measured using distance metrics in RGB color space. As image datasets grow exponentially in size—from thousands to millions of images—the choice of underlying data structure becomes critical for system performance and scalability.

Traditional approaches range from brute force linear search, which guarantees complete recall but suffers from linear time complexity, to sophisticated spatial indexing techniques that exploit the geometric properties of color space. Hash-based methods offer promising constant-time access patterns, while tree structures provide logarithmic search complexity with spatial locality advantages. However, the practical performance of these approaches in real-world scenarios often deviates significantly from theoretical predictions due to implementation details, memory hierarchy effects, and data distribution characteristics.

In this study, we present a comprehensive empirical analysis of five fundamental data structures for RGB image similarity search: Linear Search, Hash Search, Hash Dynamic Search, Octree Search, and Quadtree Search. Each algorithm was implemented in C++17 with careful attention to performance optimization and fair comparison methodology. Our experimental evaluation encompasses both controlled synthetic datasets (ranging from 100 to 50 million images) and real-world image collections, providing insights into the practical trade-offs between search speed, insertion performance, memory consumption, and precision.

\section{Theoretical Background}
\label{sec:background}

Image similarity search in RGB color space can be formalized as a nearest neighbor problem in a three-dimensional Euclidean space. Given a query point $q = (r_q, g_q, b_q)$ and a similarity threshold $\tau$, the objective is to efficiently retrieve all images $I_i = (r_i, g_i, b_i)$ such that the Euclidean distance $d(q, I_i) \leq \tau$, where:

\begin{equation}
d(q, I_i) = \sqrt{(r_q - r_i)^2 + (g_q - g_i)^2 + (b_q - b_i)^2}
\label{eq:euclidean_distance}
\end{equation}

This section presents the theoretical foundations and complexity analysis of each data structure implemented in our comparative study.

\subsection{Linear Search (Brute Force)}

Linear Search represents the baseline approach, examining every image in the dataset sequentially. Despite its simplicity, it guarantees 100\% recall and serves as the ground truth for precision evaluation.

\textbf{Time Complexity:}
\begin{itemize}
    \item Insertion: $O(1)$ - direct array append
    \item Search: $O(n)$ - sequential scan of all elements
    \item Space: $O(n)$ - stores only the image data
\end{itemize}

\subsection{Hash Search (3D Spatial Grid)}

Spatial hashing partitions the RGB color space into uniform grid cells, with each cell containing images whose RGB values fall within specific ranges. For a cell size $c$, an image $(r, g, b)$ maps to cell coordinates $(\lfloor r/c \rfloor, \lfloor g/c \rfloor, \lfloor b/c \rfloor)$.

The search process examines all cells within the query sphere by computing the set of cells that intersect with the query region defined by the similarity threshold.

\textbf{Time Complexity:}
\begin{itemize}
    \item Insertion: $O(1)$ expected - hash table insertion
    \item Search: $O(k \cdot \rho)$ where $k$ is the number of cells intersected and $\rho$ is the average cell density
    \item Space: $O(n + m)$ where $m$ is the number of active cells
\end{itemize}

\subsection{Hash Dynamic Search (Adaptive Expansion)}

Hash Dynamic Search extends the basic spatial hashing approach by implementing a dynamic expansion strategy. Starting from the query cell, the algorithm progressively examines concentric "shells" of cells at increasing Manhattan distances until the similarity threshold is satisfied or all relevant cells are processed.

The expansion proceeds by examining cells at radius $r$ defined as:
\begin{equation}
\text{Shell}_r = \{(i, j, k) : \max(|i - i_q|, |j - j_q|, |k - k_q|) = r\}
\label{eq:shell_expansion}
\end{equation}

This approach optimizes search performance by prioritizing nearby cells while maintaining precision through comprehensive coverage.

\subsection{Octree Search (3D Recursive Spatial Tree)}

Octree structures recursively partition the 3D RGB space into octants, creating a hierarchical spatial index. Each internal node represents a spatial region with eight children corresponding to the octants formed by bisecting the region along each dimension.

The search algorithm performs geometric pruning by computing the minimum distance from query point to each octant's bounding box. Octants whose minimum distance exceeds the similarity threshold are pruned from consideration.

\textbf{Time Complexity:}
\begin{itemize}
    \item Insertion: $O(\log n)$ expected, $O(h)$ where $h$ is tree height
    \item Search: $O(\log n + k)$ with geometric pruning, where $k$ is the number of results
    \item Space: $O(n + \text{internal nodes})$
\end{itemize}

\subsection{Quadtree Search (2D Spatial Tree Projection)}

Quadtree Search projects the 3D RGB similarity problem onto a 2D plane using only the red and green channels for spatial partitioning. The blue channel is considered during the final distance computation but not for tree structure determination.

This dimensional reduction strategy aims to reduce the "curse of dimensionality" effects while maintaining reasonable precision through careful threshold management during the search phase.

\section{Implementation Details}
\label{sec:implementation}

All algorithms were implemented in C++17 with careful attention to performance optimization and fair comparison methodology. The implementation employs a unified interface pattern to ensure consistent benchmarking across all data structures.

\subsection{Unified Interface Design}

Each data structure implements a common \texttt{ImageDatabase} interface:

\begin{verbatim}
class ImageDatabase {
public:
    virtual void insert(const Image& img) = 0;
    virtual std::vector<Image> findSimilar(
        const Image& query, double threshold) = 0;
    virtual std::string getName() const = 0;
};
\end{verbatim}

This design ensures fair comparison by standardizing the interface while allowing each implementation to optimize its internal data structures and algorithms.

\subsection{Memory Management Strategy}

To prevent memory-related performance artifacts and enable testing with large datasets, we implemented a CREATE→TEST→DESTROY pattern using RAII principles with smart pointers. Each data structure is instantiated, tested, and destroyed independently, preventing memory pressure from affecting subsequent tests.

\subsection{Performance Measurement}

Timing measurements utilize \texttt{std::chrono::high\_resolution\_clock} with microsecond precision. The benchmark framework separates insertion and search phases, measuring each independently to isolate performance characteristics.

\section{Experimental Methodology}
\label{sec:methodology}

Our experimental evaluation employs a rigorous methodology designed to provide fair and reproducible comparisons across all data structures.

\subsection{Synthetic Dataset Generation}

Synthetic datasets were generated using uniform random distribution in RGB space with fixed seed (20) for reproducibility. This controlled approach eliminates bias from image content while providing scalable test cases from 100 to 50 million images.

\subsection{Real Image Dataset}

Real-world validation employed a dataset of 7,721 natural images across 8 categories (airplane, car, cat, dog, flower, fruit, motorbike, person). Each image's representative RGB values were extracted from the actual pixel data, providing realistic color distributions for evaluation.

\subsection{Query Configuration}

All experiments utilized a standardized query point RGB(128, 128, 128) representing mid-gray, with a similarity threshold of 50.0 units. This configuration provides a balanced test scenario that avoids edge effects while maintaining practical relevance.

\subsection{Anti-Cache Strategy}

To prevent cache effects from biasing results toward later-executed data structures, each structure receives an independent copy of the dataset. This ensures that performance measurements reflect the true characteristics of each algorithm rather than memory system artifacts.

\section{Results and Analysis}
\label{sec:results}

This section presents comprehensive experimental results demonstrating the performance characteristics and trade-offs of each data structure across different scales and scenarios.

\subsection{Large-Scale Synthetic Performance}

Table~\ref{tab:synthetic_performance} presents performance results for synthetic datasets ranging from 1,000 to 50 million images. The results reveal distinct performance profiles for each data structure.

\begin{table}[H]
    \footnotesize 
    \centering
    \caption{Performance Comparison on Synthetic Datasets (Insertion/Search times in milliseconds)}
    \label{tab:synthetic_performance}
    \setlength{\tabcolsep}{3pt}
    \begin{tabularx}{\columnwidth}{|l|c|c|c|c|c|}
        \hline
        \textbf{Scale} & \textbf{Linear} & \textbf{Hash} & \textbf{Hash Dynamic} & \textbf{Octree} & \textbf{Quadtree} \\
        \hline
        1K & 0.082/0.005 & \textbf{0.163/0.001} & 0.165/0.002 & 0.227/0.013 & 0.148/0.011 \\
        10K & \textbf{0.750}/0.063 & 1.811/\textbf{0.001} & 1.820/0.011 & 2.270/0.088 & 2.348/0.074 \\
        100K & \textbf{6.782}/0.542 & 19.542/\textbf{0.031} & 19.680/0.098 & 28.430/0.980 & 30.286/0.917 \\
        1M & \textbf{66.646}/7.045 & 173.945/\textbf{0.187} & 174.220/0.445 & 477.827/20.957 & 365.093/15.751 \\
        50M & \textbf{5752.689}/520.698 & 42529.801/\textbf{17.987} & 42847.132/89.441 & 82092.444/2603.842 & 72793.606/1759.648 \\
        \hline
    \end{tabularx}
    \vspace{0.2cm}
    \begin{minipage}{\columnwidth}
    \footnotesize
    \textit{Format: Insertion time / Search time. Bold indicates best performance in category.}
    \end{minipage}
\end{table}

\textbf{Key Findings:}

\begin{itemize}
    \item \textbf{Insertion Dominance:} Linear Search consistently achieves the fastest insertion times across all scales, demonstrating the efficiency of direct array append operations.
    \item \textbf{Search Supremacy:} Hash Search dominates search performance, achieving remarkable scalability with only 18ms search time for 50 million images.
    \item \textbf{Dimensional Paradox:} Quadtree consistently outperforms Octree despite using fewer spatial dimensions, suggesting that the curse of dimensionality affects tree structures more than anticipated.
\end{itemize}

\subsection{Real Image Dataset Evaluation}

Real-world performance evaluation on 7,721 natural images reveals the precision-speed trade-offs inherent in approximate spatial indexing methods.

\begin{table}[H]
    \footnotesize 
    \centering
    \caption{Precision Analysis on Real Image Dataset (7,721 images)}
    \label{tab:precision_analysis}
    \setlength{\tabcolsep}{3pt}
    \begin{tabularx}{\columnwidth}{|l|c|c|c|c|}
        \hline
        \textbf{Dataset Size} & \textbf{Linear Found} & \textbf{Hash Found} & \textbf{Hash Dynamic Found} & \textbf{Precision Ratio} \\
        \hline
        500 & 171 & 146 & 171 & 85.4\% / 100\% \\
        1000 & 357 & 307 & 357 & 86.0\% / 100\% \\
        7721 & 2858 & 2471 & 2858 & 86.5\% / 100\% \\
        \hline
    \end{tabularx}
    \vspace{0.2cm}
    \begin{minipage}{\columnwidth}
    \footnotesize
    \textit{Precision Ratio: Hash Search vs Linear Search / Hash Dynamic vs Linear Search}
    \end{minipage}
\end{table>

The results demonstrate that Hash Dynamic Search achieves Linear Search precision while maintaining superior performance characteristics, making it an optimal choice for applications requiring both speed and accuracy.

\subsection{Algorithmic Trade-offs Analysis}

Our experiments reveal several unexpected findings that challenge conventional wisdom about spatial data structures:

\begin{itemize}
    \item \textbf{2D vs 3D Superiority:} Quadtree structures consistently outperformed Octree equivalents, suggesting that dimensional reduction can be beneficial in practice despite theoretical concerns.
    \item \textbf{Memory-Performance Correlation:} Proper memory management reduced RAM consumption from 40GB to 12GB while dramatically improving performance, highlighting the critical role of implementation details.
    \item \textbf{Precision-Speed Trade-off:} Hash-based methods sacrifice 14-15\% precision for significant speed improvements, requiring careful consideration of application requirements.
\end{itemize}

\section{Discussion}
\label{sec:discussion}

The experimental results provide several insights into the practical considerations for RGB image similarity search system design.

\subsection{Algorithm Selection Guidelines}

Based on our empirical analysis, we propose the following selection criteria:

\begin{itemize}
    \item \textbf{Small datasets (<5K images):} Linear Search offers simplicity and guaranteed precision
    
    \item \textbf{Medium datasets (5K-1M images):} Hash Search provides optimal search performance
    
    \item \textbf{Large datasets (>1M images):} Selection depends on precision requirements
    \begin{itemize}
        \item Speed priority: Hash Search
        \item Precision priority: Hash Dynamic Search  
        \item Balanced approach: Consider Quadtree for very large datasets
    \end{itemize}
\end{itemize}

\subsection{Theoretical vs. Practical Performance}

Our results demonstrate significant divergence between theoretical complexity predictions and practical performance. While tree structures exhibit expected logarithmic behavior, their constant factors and memory access patterns often make them inferior to simpler approaches for moderate dataset sizes.

\subsection{Implementation Impact}

The CREATE→TEST→DESTROY memory management pattern proved crucial for large-scale evaluation, reducing memory consumption by over 70\% while improving cache performance. This finding emphasizes that implementation details can be as important as algorithmic choice for practical systems.

\section{Conclusion and Future Work}
\label{sec:conclusion}

This comprehensive empirical study provides quantitative evidence for practical data structure selection in RGB image similarity search applications. Our evaluation of five distinct approaches—Linear Search, Hash Search, Hash Dynamic Search, Octree Search, and Quadtree Search—reveals that Hash-based methods achieve superior search performance while maintaining acceptable precision trade-offs.

Key contributions include: (i) comprehensive performance benchmarks across synthetic and real datasets, (ii) quantification of the precision-speed trade-off in spatial indexing methods, (iii) demonstration of the 2D vs. 3D performance paradox in tree structures, and (iv) validation of the critical importance of memory management for large-scale evaluation.

Future research directions include exploring hybrid approaches that combine multiple indexing strategies, investigating alternative distance metrics beyond Euclidean distance, and extending the analysis to other color spaces such as LAB and HSV. Additionally, parallel processing implementations could further improve performance for time-critical applications.

\section*{Author Contributions}
\label{sec:contributions}

This section details the individual contributions of each team member to the research, implementation, and analysis presented in this work.

\begin{itemize}
    \item \textbf{Luan Barbosa Rosa Carrieiros:} Led the project design and implementation architecture, developing the core benchmarking framework and unified interface design. Responsible for the Hash Dynamic Search algorithm implementation, memory management optimization strategies, and the comprehensive experimental methodology. Contributed extensively to the large-scale synthetic dataset evaluation, statistical analysis of results, and the main implementation in \texttt{main.cpp}.
    
    \item \textbf{Diego Moreira Rocha:} Focused on the implementation and optimization of tree-based data structures (Octree and Quadtree), including the geometric pruning algorithms and spatial partitioning strategies. Contributed to the real image dataset processing and evaluation framework, particularly in the precision analysis components.
    
    \item \textbf{Iago Fereguetti Ribeiro:} Responsible for the Linear Search baseline implementation and the comparative analysis methodology. Contributed to the theoretical background research, literature review, and the development of performance measurement protocols. Assisted in the preparation of experimental results and statistical validation.
    
    \item \textbf{[Nome Randomico]:} Implemented the Hash Search algorithm with 3D spatial grid indexing, including the cell mapping and collision handling strategies. Contributed to the anti-cache strategy development and participated in the scalability analysis for large datasets. Assisted in the documentation and code organization aspects of the project.
\end{itemize}

All team members participated collaboratively in the experimental design, result interpretation, and manuscript preparation, ensuring comprehensive coverage of both theoretical foundations and practical implementation considerations.

\section*{Code Availability}
\label{sec:code_availability}

The complete source code developed for this study, including implementations of all five data structures, comprehensive benchmarking framework, and experimental evaluation tools, is publicly available for reproducibility and further research. The repository includes detailed compilation instructions, usage examples, and the complete dataset specifications used in our evaluation.

Repository: \url{https://github.com/LuanCarrieiros/PAA}

This provides full transparency and enables validation of our experimental results by the research community.

% Lista todas as referências do arquivo .bib sem precisar de \cite
\nocite{*} % Inclui todas as entradas do .bib
\printbibliography[title={References}] % Imprime a bibliografia

\end{document}